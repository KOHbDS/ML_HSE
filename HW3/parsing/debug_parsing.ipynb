{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(json_list, output_file_path):\n",
    "    with open(output_file_path, 'a', encoding=\"utf-8\") as output_file:\n",
    "        for sample in json_list:\n",
    "            json_line = json.dumps(sample, ensure_ascii=False)\n",
    "            #json.dumps(sample, output_file)\n",
    "            output_file.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_topics = {\n",
    "    'Общество/Россия' : 0,\n",
    "    'Экономика' : 1,\n",
    "    'Силовые структуры' : 2,# https://russian.rt.com/trend/334946-armiya\n",
    "    'Бывший СССР' : 3,#  https://russian.rt.com/ussr/news, https://lenta.ru/rubrics/ussr\n",
    "    'Спорт' : 4,# https://russian.rt.com/sport/news\n",
    "    'Забота о себе' : 5,\n",
    "    'Строительство' : 6,\n",
    "    'Туризм/Путешествия' : 7,\n",
    "    'Наука и техника' : 8#https://russian.rt.com/science/news\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ria_topics = {\n",
    "    #\"economy\": 'Экономика', \n",
    "    #\"society\" : 'Общество/Россия', \n",
    "    #\"incidents\", \n",
    "    #\"science\": 'Наука и техника', \n",
    "    #\"culture\", \n",
    "    \"defense_safety\": 'Силовые структуры', \n",
    "    \"tourism\": 'Туризм/Путешествия'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    id: str = None\n",
    "    url: str = None\n",
    "    title: str = None\n",
    "    subtitle: str = None\n",
    "    topic: str = None\n",
    "    content: str = None\n",
    "    datetime: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "chrome_options.add_argument(\"headless\")\n",
    "chrome_options.add_argument(\"no-sandbox\")\n",
    "chrome_options.add_argument(\"disable-dev-shm-usage\")\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ria.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://ria.ru\"\n",
    "today = datetime.today()\n",
    "start_date = datetime(2023, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_html(BASE_URL, topic, step):\n",
    "    n=0\n",
    "    news = []\n",
    "    archive_date = start_date\n",
    "    iterator = tqdm(range((today - start_date).days//step), total=(today - start_date).days//step)\n",
    "    for _ in iterator:\n",
    "        try:\n",
    "            archive_url = f'{BASE_URL}/{topic}/{archive_date.strftime(\"%Y%m%d\")}'\n",
    "            driver.get(archive_url)\n",
    "            driver.execute_script(\n",
    "                        \"document.getElementsByClassName('list-more')[0].click()\"\n",
    "                    )\n",
    "            # scroll page to automatically load more articles\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    driver.execute_script(\n",
    "                        f\"window.scrollTo(0, document.body.scrollHeight - 1200)\"\n",
    "                    )\n",
    "                    time.sleep(0.25)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            scope = soup.find(\n",
    "                \"div\", {\"class\": \"list\", \"itemtype\": \"http://schema.org/ItemList\"}\n",
    "            )\n",
    "            news += scope.find_all(\"div\", {\"class\": \"list-item\"})\n",
    "            archive_date += timedelta(step)\n",
    "        except:\n",
    "            n+=1\n",
    "            iterator.set_description(f'skip_dates={n}')\n",
    "            continue\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_page(page, topic):\n",
    "    try:\n",
    "        \"\"\"Extract from page desired fields\"\"\"\n",
    "\n",
    "        # Create article data class object\n",
    "        article = Article()\n",
    "        article.topic = ria_topics[topic]\n",
    "\n",
    "        # article url\n",
    "        article.url = page.find(\"a\", {\"class\": \"list-item__image\"})[\"href\"]\n",
    "\n",
    "        # article id\n",
    "        s = re.findall(r\"\\d+.html\", article.url)[0]\n",
    "        article.id = s[: s.find(\".\")]\n",
    "\n",
    "        # load page\n",
    "        driver.get(article.url)\n",
    "        time.sleep(1)\n",
    "        html = driver.page_source\n",
    "\n",
    "        # article source\n",
    "        source = article.url[8 : article.url.find(\".\")]\n",
    "\n",
    "        # article object\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        obj = soup.find(\n",
    "            \"div\",\n",
    "            {\n",
    "                \"class\": lambda x: x and (x.find(f\"article m-article m-{source}\") > -1),\n",
    "                \"data-article-id\": article.id,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        if not obj:\n",
    "            obj = soup.find(\n",
    "                \"div\",\n",
    "                {\n",
    "                    \"class\": lambda x: x and (x.find(f\"article m-video m-{source}\") > -1),\n",
    "                    \"data-article-id\": article.id,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        # process article title\n",
    "        title = obj.find(\"div\", {\"class\": \"article__title\"})\n",
    "        title_2 = obj.find(\"h1\", {\"class\": \"article__title\"})\n",
    "\n",
    "        if title:\n",
    "            article.title = title.text\n",
    "        else:\n",
    "            article.title = title_2.text if title_2 else \"\"\n",
    "\n",
    "        # article subtitle\n",
    "        subtitle = obj.find(\"h1\", {\"class\": \"article__second-title\"})\n",
    "        article.subtitle = subtitle.text if subtitle else \"\"\n",
    "\n",
    "        # article content\n",
    "        article.content = obj.find(\n",
    "            \"div\", {\"class\": \"article__body js-mediator-article mia-analytics\"}\n",
    "        ).text\n",
    "\n",
    "        # article datetime\n",
    "        article.datetime = obj.find(\"div\", {\"class\": \"article__info-date\"}).find(\"a\").text\n",
    "\n",
    "        # article number of views\n",
    "        # article.views = int(obj.find('span', {'class': 'statistic__item m-views'}).text)\n",
    "\n",
    "        return article\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ria_topics = {\n",
    "    #\"economy\": 'Экономика', \n",
    "    #\"society\" : 'Общество/Россия', \n",
    "    #\"incidents\", \n",
    "    #\"science\": 'Наука и техника', \n",
    "    #\"culture\", \n",
    "    \"defense_safety\": 'Силовые структуры', \n",
    "    \"tourism\": 'Туризм/Путешествия'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097d596b432549879cd87bedd9fddddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c623ee8e1ce428fb5b86fff375bc906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_save = '/workspaces/ML_HSE/HW3/parsing/data/ria_news/'\n",
    "for topic, topic_ru in ria_topics.items():\n",
    "    topic_news = get_topic_html(BASE_URL, topic, 5)\n",
    "    random.shuffle(topic_news)\n",
    "    iterator2 = tqdm(topic_news, total=len(topic_news))\n",
    "    parsed_topic_news = [await parse_page(page, topic) for page in iterator2]\n",
    "    \n",
    "    save_jsonl([i.__dict__ for i in parsed_topic_news if i], path_to_save+f'ria_{topic}.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Lenta.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    id: str = None\n",
    "    url: str = None\n",
    "    title: str = None\n",
    "    subtitle: str = None\n",
    "    topic: str = None\n",
    "    content: str = None\n",
    "    datetime: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_topics = {\n",
    "    1 : 'Общество',\n",
    "    4 : 'Экономика',\n",
    "    37 : 'Силовые структуры',\n",
    "    3 : 'Бывший СССР',\n",
    "    8 : 'Спорт',\n",
    "    87: 'Забота о себе',\n",
    "    48: 'Туризм',\n",
    "    5 : 'Наука и техника'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_66597/920157527.py:6: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "class lentaRu_parser:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _get_url(self, param_dict: dict) -> str:\n",
    "        \"\"\"\n",
    "        Возвращает URL для запроса json таблицы со статьями\n",
    "\n",
    "        url = 'https://lenta.ru/search/v2/process?'\\\n",
    "        + 'from=0&'\\                       # Смещение\n",
    "        + 'size=1000&'\\                    # Кол-во статей\n",
    "        + 'sort=2&'\\                       # Сортировка по дате (2), по релевантности (1)\n",
    "        + 'title_only=0&'\\                 # Точная фраза в заголовке\n",
    "        + 'domain=1&'\\                     # ??\n",
    "        + 'modified%2Cformat=yyyy-MM-dd&'\\ # Формат даты\n",
    "        + 'type=1&'\\                       # Материалы. Все материалы (0). Новость (1)\n",
    "        + 'bloc=4&'\\                       # Рубрика. Экономика (4). Все рубрики (0)\n",
    "        + 'modified%2Cfrom=2020-01-01&'\\\n",
    "        + 'modified%2Cto=2020-11-01&'\\\n",
    "        + 'query='                         # Поисковой запрос\n",
    "        \"\"\"\n",
    "        hasType = int(param_dict['type']) != 0\n",
    "        hasBloc = int(param_dict['bloc']) != 0\n",
    "\n",
    "        url = 'https://lenta.ru/search/v2/process?'\\\n",
    "        + 'from={}&'.format(param_dict['from'])\\\n",
    "        + 'size={}&'.format(param_dict['size'])\\\n",
    "        + 'sort={}&'.format(param_dict['sort'])\\\n",
    "        + 'title_only={}&'.format(param_dict['title_only'])\\\n",
    "        + 'domain={}&'.format(param_dict['domain'])\\\n",
    "        + 'modified%2Cformat=yyyy-MM-dd&'\\\n",
    "        + 'type={}&'.format(param_dict['type']) * hasType\\\n",
    "        + 'bloc={}&'.format(param_dict['bloc']) * hasBloc\\\n",
    "        + 'modified%2Cfrom={}&'.format(param_dict['dateFrom'])\\\n",
    "        + 'modified%2Cto={}&'.format(param_dict['dateTo'])\\\n",
    "        + 'query={}'.format(param_dict['query'])\n",
    "\n",
    "        return url\n",
    "\n",
    "\n",
    "    def _get_search_table(self, param_dict: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Возвращает pd.DataFrame со списком статей\n",
    "        \"\"\"\n",
    "        url = self._get_url(param_dict)\n",
    "        r = rq.get(url)\n",
    "        search_table = [\n",
    "            {\n",
    "                'id': i.pop('docid'), \n",
    "                'url': i.pop('url'), \n",
    "                'title': i.pop('title'), \n",
    "                'subtitle': None, \n",
    "                'topic': lenta_topics[i.pop('bloc')], \n",
    "                'content': i.pop('text'), \n",
    "                'datetime': datetime.fromtimestamp(i.pop('modified')).strftime('%H:%M %d.%m.%Y')\n",
    "                } for i in r.json()['matches']\n",
    "            ]\n",
    "\n",
    "        return search_table\n",
    "\n",
    "\n",
    "    def get_articles(self,\n",
    "                     param_dict,\n",
    "                     time_step = 37,):\n",
    "        \"\"\"\n",
    "        Функция для скачивания статей интервалами через каждые time_step дней\n",
    "        Делает сохранение таблицы через каждые save_every * time_step дней\n",
    "\n",
    "        param_dict: dict\n",
    "        ### Параметры запроса\n",
    "        ###### project - раздел поиска, например, rbcnews\n",
    "        ###### category - категория поиска, например, TopRbcRu_economics\n",
    "        ###### dateFrom - с даты\n",
    "        ###### dateTo - по дату\n",
    "        ###### offset - смещение поисковой выдачи\n",
    "        ###### limit - лимит статей, максимум 100\n",
    "        ###### query - поисковой запрос (ключевое слово), например, РБК\n",
    "\n",
    "        \"\"\"\n",
    "        param_copy = param_dict.copy()\n",
    "        timedelta_s = param_copy.pop('timedelta_step')\n",
    "        time_step = timedelta(days=time_step)\n",
    "        dateFrom = datetime.strptime(param_copy['dateFrom'], '%Y-%m-%d')\n",
    "        dateTo = datetime.strptime(param_copy['dateTo'], '%Y-%m-%d')\n",
    "        if dateFrom > dateTo:\n",
    "            raise ValueError('dateFrom should be less than dateTo')\n",
    "\n",
    "        out = []\n",
    "        save_counter = 0\n",
    "\n",
    "        while dateFrom <= dateTo:\n",
    "            param_copy['dateTo'] = (dateFrom + time_step).strftime('%Y-%m-%d')\n",
    "            if dateFrom + time_step > dateTo:\n",
    "                param_copy['dateTo'] = dateTo.strftime('%Y-%m-%d')\n",
    "            print('Parsing articles from ' + param_copy['dateFrom'] +  ' to ' + param_copy['dateTo'])\n",
    "            out+= self._get_search_table(param_copy)\n",
    "            dateFrom += time_step + timedelta(days=timedelta_s)\n",
    "            param_copy['dateFrom'] = dateFrom.strftime('%Y-%m-%d')\n",
    "            save_counter += 1\n",
    "\n",
    "        save_jsonl(out, work_path.joinpath('data/lenta').joinpath(f'lenta_{lenta_topics[int(param_dict[\"bloc\"])]}.jsonl')\n",
    "        print('Finish')\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_dict: {'query': 'РБК', 'timedelta_step': 3, 'from': '0', 'size': '1000', 'dateFrom': '2023-01-01', 'dateTo': '2024-12-23', 'sort': '3', 'title_only': '0', 'type': '0', 'bloc': '1', 'domain': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Задаем тут параметры\n",
    "query = 'РБК'\n",
    "offset = 0\n",
    "size = 1000\n",
    "sort = \"3\"\n",
    "title_only = \"0\"\n",
    "domain = \"1\"\n",
    "material = \"0\"\n",
    "bloc = \"1\" # topic = тематика новости\n",
    "dateFrom = '2023-01-01'\n",
    "dateTo = \"2024-12-23\"\n",
    "timedelta_step = 3\n",
    "\n",
    "param_dict = {'query'     : query,\n",
    "              'timedelta_step': timedelta_step,\n",
    "              'from'      : str(offset),\n",
    "              'size'      : str(size),\n",
    "              'dateFrom'  : dateFrom,\n",
    "              'dateTo'    : dateTo,\n",
    "              'sort'      : sort,\n",
    "              'title_only': title_only,\n",
    "              'type'      : material,\n",
    "              'bloc'      : bloc,\n",
    "              'domain'    : domain}\n",
    "\n",
    "print(\"param_dict:\", param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Общество = 625\n",
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Экономика = 1996\n",
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Силовые структуры = 291\n",
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Бывший СССР = 634\n",
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Спорт = 103\n",
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Забота о себе = 4\n",
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Туризм = 121\n",
      "Parsing articles from 2023-01-01 to 2023-06-30\n",
      "Parsing articles from 2023-07-03 to 2023-12-30\n",
      "Parsing articles from 2024-01-02 to 2024-06-30\n",
      "Parsing articles from 2024-07-03 to 2024-12-23\n",
      "Finish\n",
      "DONE Наука и техника = 44\n"
     ]
    }
   ],
   "source": [
    "for bloc_topic in lenta_topics:\n",
    "    param_dict.update({'bloc': bloc_topic})\n",
    "    parser = lentaRu_parser()\n",
    "    tbl = parser.get_articles(param_dict=param_dict,\n",
    "                              time_step = 180)\n",
    "    print(f'DONE {lenta_topics[bloc_topic]} = {len(tbl)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
